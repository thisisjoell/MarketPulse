# Home.py  (Home)
import os
from datetime import date, timedelta
import numpy as np
import pandas as pd
import streamlit as st
from dotenv import load_dotenv
import viz          # animated + sparkline + colour‑line helpers

import shared       # fetch_price_and_trend · calc_mini_forecast · detect_divergences, etc.
import alpha_lab    # still needed for session strategies later
import models       # if needed

load_dotenv()
st.set_page_config(page_title="MarketPulse", page_icon="📈", layout="wide")

# ------------------------------------------------------------------
# Environment & prefs
# ------------------------------------------------------------------
has_key = shared.sync_api_keys()
if not has_key:
    st.sidebar.warning("No OpenAI key set — summaries will show a warning.")

pro_mode = shared.sidebar_mode_toggle()

# ------------------------------------------------------------------
# Global header (ticker + date‑range selectors)
# ------------------------------------------------------------------
shared.global_header()
ticker = st.session_state["ticker"]
start_date, end_date = st.session_state["date_range"]

# ------------------------------------------------------------------
# Fetch action
# ------------------------------------------------------------------
fetch_btn = st.button("📥 Fetch Data & Sentiment", type="primary")
st.markdown("---")

# ──────────────────────────────────────────────────────────────────
# detect if we already have data from a previous run
# ──────────────────────────────────────────────────────────────────
data_ready = all(k in st.session_state for k in ("price_daily", "trend", "posts"))

if fetch_btn:
    try:
        with st.spinner("Loading price & Reddit data…"):
            price_daily, trend_df, posts_df = shared.fetch_price_and_trend(
                ticker, start_date, end_date
            )
    except Exception as e:
        st.error(f"Fetch failed: {e}")
        st.stop()

    # persist for use across pages
    st.session_state["price_daily"] = price_daily
    st.session_state["trend"]       = trend_df
    st.session_state["posts"]       = posts_df
    data_ready = True                # now have data in session

    # freshness chip + toast
    shared.mark_data_fetched()
    ph = st.session_state.get("_freshness_ph")
    if ph is not None:
        shared._render_data_freshness_chip(ph)

    st.toast(f"Data loaded: {len(price_daily)} days, {len(posts_df)} posts.", icon="🟢")

# ------------------------------------------------------------------
# Render analytics only when data is available
# ------------------------------------------------------------------
if data_ready:
    price_daily = st.session_state["price_daily"]
    trend_df    = st.session_state["trend"]
    posts_df    = st.session_state["posts"]

    # ------------------------------------------------------------------
    # ✴ MINI FORECAST (1‑d LR from sentiment)
    # ------------------------------------------------------------------
    pred      = shared.calc_mini_forecast(trend_df, price_daily, min_obs=10)
    pred_pct  = pred if pred is not None else np.nan

    # KPI inputs
    price_today = price_daily.iloc[-1]
    price_prev  = price_daily.iloc[-2] if len(price_daily) > 1 else price_today
    delta_pct   = (price_today / price_prev - 1) if price_prev != 0 else 0.0
    sent_daily  = trend_df.iloc[-1]["sentiment"] if not trend_df.empty else np.nan
    vol_10      = price_daily.pct_change().rolling(10).std().iloc[-1]

    # KPI strip
    kpi1, kpi2, kpi3, kpi4 = st.columns(4, gap="small")
    kpi1.metric("Last Price", f"${price_today:,.2f}", f"{delta_pct:+.2%}")
    kpi2.metric("Sentiment ⇡", f"{sent_daily:+.2f}" if pd.notna(sent_daily) else "n/a")
    kpi3.metric(
        "1‑d Forecast",
        f"{pred_pct:+.2%}" if pd.notna(pred_pct) else "n/a",
        help="Mini‑forecast is generated by a logistic‑regression model trained on recent sentiment vs returns."
    )
    kpi4.metric(
        "Vol Spike",
        f"{vol_10:.2%}" if pd.notna(vol_10) else "n/a",
        help="10‑day rolling std of daily returns."
    )
    st.markdown("---")

    # ------------------------------------------------------------------
    # ✴ DIVERGENCE / ANOMALY DETECTION
    # ------------------------------------------------------------------
    div = shared.detect_divergences(price_daily, trend_df)

    # Two‑lane layout
    col_main, col_side = st.columns([3, 1], gap="large")

    with col_main:
        if div.get("neg_flags", 0) >= 2:
            st.warning("🚨 **Divergence:** Price weakness vs bullish sentiment (≥2 signals).")
        if div.get("pos_flags", 0) >= 2:
            st.info("📈 **Early Breakout:** Price pop on muted / falling sentiment (≥2 signals).")

        # ──────────────────────────────────────────────────────────────
        # Friendly diagnostics (no Pro‑mode requirement)
        # ──────────────────────────────────────────────────────────────
        if st.checkbox("Show divergence diagnostics", key="show_div_diag"):
            st.markdown("#### Diagnostics overview")
            st.write(
                f"**Negative flags:** {div['neg_flags']} &nbsp;&nbsp;|&nbsp;&nbsp; "
                f"**Positive flags:** {div['pos_flags']}"
            )

            # rules table
            rule_labels = {
                "z_score_neg":        "Big down‑day (|z|)",
                "sent_jump":          "Sentiment jump ↑",
                "sent_vs_price":      "Bullish sent ↔ price ↓",
                "corr_neg":           "Neg. 7‑day corr",
                "z_score_pos":        "Big up‑day (|z|)",
                "sent_muted":         "Sentiment muted",
                "sent_dn_price_up":   "Sent ↓ / Price ↑",
                "corr_flat":          "Low 7‑day corr",
            }
            rules_df = pd.DataFrame(
                [
                    {
                        "Rule": rule_labels.get(k, k),
                        "Triggered": "✅" if v else ""
                    }
                    for k, v in div.get("rules", {}).items()
                ]
            )
            shared.mp_table(rules_df, small=True)

            # numeric context
            ctx_df = pd.DataFrame(
                {
                    "Metric": [
                        "Sentiment today",
                        "Sentiment prev‑day",
                        "Price change %",
                        "Z‑score",
                        "7‑day corr (ρ)",
                    ],
                    "Value": [
                        f"{div['sent_today']:+.2f}",
                        f"{div['sent_prev']:+.2f}",
                        f"{div['pct_today']:+.2%}",
                        f"{div['z_score']:+.2f}",
                        f"{div['corr7']:+.2f}",
                    ],
                }
            )
            shared.mp_table(ctx_df, small=True)

        # main charts
        shared.plot_price(price_daily.to_frame("Close"), ticker)
        st.subheader("Daily sentiment trend")
        shared.show_trend(trend_df)

        # —— NEW: price coloured by sentiment (moved here) ——
        st.subheader("Price coloured by sentiment")
        fig_colour = viz.price_line_by_sentiment(price_daily, trend_df)
        st.plotly_chart(fig_colour, use_container_width=True)

    with col_side:
        st.subheader("Latest Reddit chatter")
        # show only top 8 rows for compactness
        shared.show_table(posts_df.head(8))
        st.subheader("Summary")
        top10 = shared.top_posts_hybrid(posts_df, k=10, tau_hrs=72)
        with st.spinner("Summarizing…"):
            st.write(shared.gpt_summary(ticker, top10))
        st.subheader("Distribution")
        shared.show_dist(posts_df)

else:
    st.info("Click **Fetch Data & Sentiment** to start.")

# ------------------------------------------------------------------
# Footer
# ------------------------------------------------------------------
st.caption("Data: Yahoo Finance & Reddit • Sentiment: RoBERTa + VADER • MarketPulse 2025")


